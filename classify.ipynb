{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Python 3.7.7\n"
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据到内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\nblues\nclassical\ncountry\ndisco\nhiphop\njazz\nmetal\npop\nreggae\nrock\n"
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "data_set = []\n",
    "label_set = []\n",
    "label2id = {genre:i for i,genre in enumerate(genres)}\n",
    "id2label = {i:genre for i,genre in enumerate(genres)}\n",
    "print(label2id)\n",
    "for g in genres:\n",
    "    print(g)\n",
    "    for filename in os.listdir(f'../dataset/genres/{g}/'):\n",
    "        songname = f'../dataset/genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        data_set.append([float(i) for i in to_append.split(\" \")])\n",
    "        label_set.append(label2id[g])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import np_utils\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data_set, dtype = float))\n",
    "y = np_utils.to_categorical(np.array(label_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X.shape:  (1000, 26)  Y.shape: (1000, 10)\n"
    }
   ],
   "source": [
    "print(\"X.shape: \", X.shape, \" Y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将测试集和训练集分隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.layers import Dense, Dropout\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里创建了一个包含三个隐藏层的神经网络，最后一层输出的是分类层，因为是10类，所以最后一层是10个单元。（这里增加了一层Dropout减少数据过拟合）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编译模型\n",
    "\n",
    "这里是一个分类问题，所以使用类别交叉熵函数`categorical_crossentropy`，然后优化器选择`Adam`，评价指标选择正确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与评估\n",
    "\n",
    "接下来使用`fit`方法进行训练，训练50轮。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n800/800 [==============================] - 1s 690us/step - loss: 2.2582 - accuracy: 0.1813\nEpoch 2/50\n800/800 [==============================] - 0s 58us/step - loss: 2.0312 - accuracy: 0.3150\nEpoch 3/50\n800/800 [==============================] - 0s 57us/step - loss: 1.8582 - accuracy: 0.3562\nEpoch 4/50\n800/800 [==============================] - 0s 83us/step - loss: 1.7381 - accuracy: 0.3900\nEpoch 5/50\n800/800 [==============================] - 0s 84us/step - loss: 1.6293 - accuracy: 0.4250\nEpoch 6/50\n800/800 [==============================] - 0s 78us/step - loss: 1.5447 - accuracy: 0.4387\nEpoch 7/50\n800/800 [==============================] - 0s 67us/step - loss: 1.4948 - accuracy: 0.4750\nEpoch 8/50\n800/800 [==============================] - 0s 80us/step - loss: 1.4412 - accuracy: 0.4900\nEpoch 9/50\n800/800 [==============================] - 0s 78us/step - loss: 1.3488 - accuracy: 0.5300\nEpoch 10/50\n800/800 [==============================] - 0s 54us/step - loss: 1.3170 - accuracy: 0.5437\nEpoch 11/50\n800/800 [==============================] - 0s 106us/step - loss: 1.2462 - accuracy: 0.5813\nEpoch 12/50\n800/800 [==============================] - 0s 75us/step - loss: 1.1976 - accuracy: 0.5863\nEpoch 13/50\n800/800 [==============================] - 0s 72us/step - loss: 1.1739 - accuracy: 0.6112\nEpoch 14/50\n800/800 [==============================] - 0s 51us/step - loss: 1.1123 - accuracy: 0.6150\nEpoch 15/50\n800/800 [==============================] - 0s 54us/step - loss: 1.0844 - accuracy: 0.6325\nEpoch 16/50\n800/800 [==============================] - 0s 61us/step - loss: 1.0453 - accuracy: 0.6463\nEpoch 17/50\n800/800 [==============================] - 0s 66us/step - loss: 1.0244 - accuracy: 0.6575\nEpoch 18/50\n800/800 [==============================] - 0s 57us/step - loss: 0.9704 - accuracy: 0.6687\nEpoch 19/50\n800/800 [==============================] - 0s 56us/step - loss: 0.9695 - accuracy: 0.6775\nEpoch 20/50\n800/800 [==============================] - 0s 61us/step - loss: 0.9189 - accuracy: 0.6925\nEpoch 21/50\n800/800 [==============================] - 0s 77us/step - loss: 0.8751 - accuracy: 0.7163\nEpoch 22/50\n800/800 [==============================] - 0s 51us/step - loss: 0.9167 - accuracy: 0.6888\nEpoch 23/50\n800/800 [==============================] - 0s 61us/step - loss: 0.8620 - accuracy: 0.7350\nEpoch 24/50\n800/800 [==============================] - 0s 79us/step - loss: 0.8092 - accuracy: 0.7250\nEpoch 25/50\n800/800 [==============================] - 0s 61us/step - loss: 0.8058 - accuracy: 0.7337\nEpoch 26/50\n800/800 [==============================] - 0s 66us/step - loss: 0.8150 - accuracy: 0.7400\nEpoch 27/50\n800/800 [==============================] - 0s 48us/step - loss: 0.7318 - accuracy: 0.7588\nEpoch 28/50\n800/800 [==============================] - 0s 68us/step - loss: 0.7348 - accuracy: 0.7563\nEpoch 29/50\n800/800 [==============================] - 0s 68us/step - loss: 0.7427 - accuracy: 0.7437\nEpoch 30/50\n800/800 [==============================] - 0s 67us/step - loss: 0.7217 - accuracy: 0.7725\nEpoch 31/50\n800/800 [==============================] - 0s 55us/step - loss: 0.7012 - accuracy: 0.7738\nEpoch 32/50\n800/800 [==============================] - 0s 55us/step - loss: 0.6386 - accuracy: 0.8012\nEpoch 33/50\n800/800 [==============================] - 0s 45us/step - loss: 0.6710 - accuracy: 0.7775\nEpoch 34/50\n800/800 [==============================] - 0s 59us/step - loss: 0.6179 - accuracy: 0.8012\nEpoch 35/50\n800/800 [==============================] - 0s 61us/step - loss: 0.6012 - accuracy: 0.8112\nEpoch 36/50\n800/800 [==============================] - 0s 61us/step - loss: 0.6025 - accuracy: 0.7975\nEpoch 37/50\n800/800 [==============================] - 0s 52us/step - loss: 0.5784 - accuracy: 0.8150\nEpoch 38/50\n800/800 [==============================] - 0s 52us/step - loss: 0.5511 - accuracy: 0.8225\nEpoch 39/50\n800/800 [==============================] - 0s 52us/step - loss: 0.5394 - accuracy: 0.8213\nEpoch 40/50\n800/800 [==============================] - 0s 72us/step - loss: 0.5388 - accuracy: 0.8213\nEpoch 41/50\n800/800 [==============================] - 0s 85us/step - loss: 0.5294 - accuracy: 0.8338\nEpoch 42/50\n800/800 [==============================] - 0s 103us/step - loss: 0.5303 - accuracy: 0.8363\nEpoch 43/50\n800/800 [==============================] - 0s 87us/step - loss: 0.5116 - accuracy: 0.8338\nEpoch 44/50\n800/800 [==============================] - 0s 62us/step - loss: 0.4800 - accuracy: 0.8600\nEpoch 45/50\n800/800 [==============================] - 0s 67us/step - loss: 0.4615 - accuracy: 0.8662\nEpoch 46/50\n800/800 [==============================] - 0s 136us/step - loss: 0.4655 - accuracy: 0.8462\nEpoch 47/50\n800/800 [==============================] - 0s 90us/step - loss: 0.4521 - accuracy: 0.8562\nEpoch 48/50\n800/800 [==============================] - 0s 99us/step - loss: 0.4254 - accuracy: 0.8775\nEpoch 49/50\n800/800 [==============================] - 0s 81us/step - loss: 0.4174 - accuracy: 0.8687\nEpoch 50/50\n800/800 [==============================] - 0s 97us/step - loss: 0.4125 - accuracy: 0.8800\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x7fdfb01a9350>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`evaluate`方法进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "200/200 [==============================] - 0s 316us/step\ntest_acc:  0.6349999904632568\n"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}